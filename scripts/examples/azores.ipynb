{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74389b29-6e27-402f-a403-2476d23d5be3",
   "metadata": {},
   "source": [
    "__Note__: to see the output of this notebook, see the [azores.md file](../../results/examples/azores/azores.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122bdf2-9aef-4a23-9a74-3da9921f6ad0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "__The goal__:  We're going to (loosely) reproduce results from Cresswell-Clay et al. (2022)$^1$ from scratch, using data stored on WHOI's CMIP server. \n",
    "\n",
    "__What did this study do?__  Cresswell-Clay et al. compared the observed expansion of the Azores High over the last $\\sim$100 years with its variability on longer timescales. The central question is whether this expansion can be attributed to external forcing (e.g., greenhouse gas emissions) or could be explained by natural climate variability.\n",
    "\n",
    "To address this question, Cresswell-Clay et al. compare the magnitude of the Azores High's recent expansion to its simulated variability in an ensemble of $\\sim$1,200 year simulations from a global climate model (the Community Earth System Model Last-Millenium Ensemble, or CESM-LME). They also compare the model's reconstruction of Azores High extent over this period to a paleoclimate \"proxy\" (a $\\sim$1200-year record of $\\delta^{13}C$ obtained from a stalagmite in a Portuguese cave)$^2$. As suggested in the paper's title, the authors find the recent expansion is \"unprecedented\" and very unlikely to occur from natural climate variability.\n",
    "\n",
    "__What is the Azores High?__ A \"local maximum\" of surface air pressure, located approximately over the Azores Islands (about 1,500 km west of Portugal, in the North Atlantic Ocean) during the winter months. \n",
    "\n",
    "__Why does it expansion matter?__ One reason: high pressure is associated with drier conditions (e.g., less rain). If the high pressure region expands, we might expect regions in the \"expansion zone\" to become drier.\n",
    "\n",
    "__What are we going to do?__ We're going to reproduce versions of Figs. 1, 2c, and 3d-e, from scratch (the authors' original code is also available online$^3$). The goal is to provide a practical example of how to use reanalysis and climate model output to answer questions about climate. \n",
    "\n",
    "__References__  \n",
    "$^1$Cresswell-Clay, N. et al. (2022). \"Twentieth-century Azores High expansion unprecedented in the past 1,200 years\". *Nat. Geosci.* 15, 548–553.  \n",
    "$^2$Thatcher, D. L. et al. (2023) \"Iberian hydroclimate variability and the Azores High during the last 1200 years: evidence from proxy records and climate model simulations\". *Clim Dyn* 60, 2365–2387.  \n",
    "$^3$https://github.com/nathanielcresswellclay/AzoresHighExpansion/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0650c59a-8972-41a7-998b-c32485914c7a",
   "metadata": {},
   "source": [
    "# Outline\n",
    "This example is divided into three segments:\n",
    "1. __Obtaining and pre-processing the data__: we'll load global data from WHOI's CMIP server,  \"reduce\" it by trimming in time and space, and save the pre-processed data locally. While not always possible, saving a reduced version of the data can speed up subsequent analysis: the code will run much faster if we can fit the data into \"memory\" (i.e., random access memory, or RAM).\n",
    "2. __\"Observed\" expansion and model validation__: we'll plot the \"observed\" expansion of the Azores High – based on reanalysis output – and compare it to the expansion simulated by the CESM-LME over the overlapping period (approximately 1850-2005). The motivating question is: can we trust the model over the period where it *doesn't* overlap with observations?\n",
    "3. __Analysis of model output and comparison to cave record__: we'll compare statistics between CESM-LME ensembles with different \"external forcing\". In particular, we'll look at four types of forcing: (a) greenhouse gas emissions, (b) orbital/solar variability, (c) volcanic activity, and (d) all of the above (denoted \"Full\" in the paper). We'll also compare the Azores High variability \"Full\" forcing scenario to the $\\delta^{13}C$ variability in the Portuguese stalagmite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b35aa8-7384-4906-9d77-f463ff0cebc2",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e13d2c-e10b-4b5b-8f75-7a70dc1be3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mticker\n",
    "import cmocean\n",
    "import xesmf as xe\n",
    "import os\n",
    "\n",
    "## custom imports\n",
    "import src.utils\n",
    "import src.utils_azores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07517718-7cad-49ae-a03a-2e8d9d3f0910",
   "metadata": {},
   "source": [
    "# Define constants/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a0834-084d-487d-b868-d1728c067148",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filepaths\n",
    "# where to save data locally\n",
    "DATA_FP = \"/home/kcarr/whoi-climate-data-tutorial/data\"\n",
    "\n",
    "# on clidex\n",
    "fp_lme = \"/vortex/clidex/data/model/CESM/LME/atm/psl\"\n",
    "\n",
    "# on cmip5 server\n",
    "fp_slp_era = \"/mnt/cmip5-data/reanalysis/era.20c/sfc/msl/moda/msl.mon.mean.nc\"\n",
    "fp_slp_noaa = \"/mnt/cmip5-data/reanalysis/noaa.cires.20crv2c/monolevel/prmsl/monthly/prmsl.mon.mean.nc\"\n",
    "\n",
    "# # also potentially useful:\n",
    "# # (note: LME only has single ensemble member at the given directory)\n",
    "# lme_fp = \"/mnt/cmip5-data/CMIP5/output1/NCAR/CCSM4/past1000/mon/atmos/Amon/r1i1p1/psl/psl_Amon_CCSM4_past1000_r1i1p1_085001-185012.nc\"\n",
    "# era_fp = \"/vortexfs1/share/clidex/data/reanalysis/20CR/prmsl/prmsl.mon.mean.nc\"\n",
    "\n",
    "## Set plotting defaults\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d2cae-bd42-4433-9666-2c9a86b8141d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2aa9b-746b-4c3f-8b62-fc87265b5829",
   "metadata": {},
   "source": [
    "## Datasets used:\n",
    "- ERA-20C\n",
    "- NOAA–CIRES 20CR\n",
    "- HadSLP2\n",
    "- CESM1 LME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339f345-4d61-4958-94c7-2c97d5c180ee",
   "metadata": {},
   "source": [
    "### Functions for fetching 'raw' data from server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dacba5-dcd4-4bbe-b9a4-cd51256e2a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_lme_member(forcing_type, member_id):\n",
    "    \"\"\"\n",
    "    Function loads data from single member of CESM last-millenium ensemble (LME).\n",
    "    Args:\n",
    "    - 'member_id' is integer in [1,13] specifying which ensemble member to load\n",
    "    - 'forcing_type' is one of {\"all\",\"volcanic\",\"GHG\",\"orbital\"}\n",
    "    \"\"\"\n",
    "\n",
    "    ## get prefix\n",
    "    lme_fp = \"/vortex/clidex/data/model/CESM/LME/atm/psl\"\n",
    "    prefix = \"b.e11.BLMTRC5CN.f19_g16\"\n",
    "    if forcing_type == \"all\":\n",
    "        pass\n",
    "\n",
    "    elif forcing_type == \"GHG\":\n",
    "        prefix = f\"{prefix}.GHG\"\n",
    "\n",
    "    elif forcing_type == \"volcanic\":\n",
    "        prefix = f\"{prefix}.VOLC_GRA\"\n",
    "\n",
    "    elif forcing_type == \"orbital\":\n",
    "        prefix = f\"{prefix}.ORBITAL\"\n",
    "\n",
    "    else:\n",
    "        print(\"Error: not a valid forcing type\")\n",
    "        return\n",
    "\n",
    "    ## Get names of two files for each ensemble member\n",
    "    fp_and_prefix = f\"{lme_fp}/{prefix}.{member_id:03d}.cam.h0.PSL\"\n",
    "    fp0 = f\"{fp_and_prefix}.085001-184912.nc\"\n",
    "    fp1 = f\"{fp_and_prefix}.185001-200512.nc\"\n",
    "\n",
    "    ## Load data\n",
    "    data = xr.open_mfdataset([fp0, fp1], chunks={\"time\": 2000})[\"PSL\"]\n",
    "\n",
    "    ## switch longitude range from [0,360) to (-180,180]\n",
    "    data = src.utils.switch_longitude_range(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_noaa():\n",
    "    \"\"\"NOAA CIRES data and update coordinates\"\"\"\n",
    "\n",
    "    ## open raw data and select PSL variable\n",
    "    data = xr.open_dataset(fp_slp_noaa)[\"prmsl\"]\n",
    "\n",
    "    ## switch longitude range from [0,360) to (-180,180]\n",
    "    data = src.utils.switch_longitude_range(data)\n",
    "\n",
    "    ## reverse latitude direction from [90,-90] to [-90,90]\n",
    "    data = src.utils.reverse_latitude(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_era():\n",
    "\n",
    "    ## open raw data and select PSL file\n",
    "    data = xr.open_dataarray(fp_slp_era)\n",
    "\n",
    "    ## rename coordinates from \"latitude\" and \"longitude\"\n",
    "    ## to \"lat\" and \"lon\"\n",
    "    data = data.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "    ## switch longitude range from [0,360) to (-180,180]\n",
    "    data = src.utils.switch_longitude_range(data)\n",
    "\n",
    "    ## reverse latitude direction from [90,-90] to [-90,90]\n",
    "    data = src.utils.reverse_latitude(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0d3ae-fdeb-461c-92af-066469610b69",
   "metadata": {},
   "source": [
    "### Functions to trim raw data and save locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ac55f-b224-4624-b56e-f6b10ef8375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each dataset, get DJF average and trim to North Atlantic\n",
    "def trim(data):\n",
    "    \"\"\"function to trim a data in time and space, and save to file.\n",
    "    Two datasets are returned:\n",
    "    - data_trim (trimmed to north atlantic)\n",
    "    - data_global_avg (global averaged of data)\"\"\"\n",
    "\n",
    "    ## trim in time, then load to memory\n",
    "    data_djf = src.utils.djf_avg(data).compute()\n",
    "\n",
    "    ## trim in space\n",
    "    data_trim = src.utils_azores.trim_to_north_atlantic(data_djf)\n",
    "\n",
    "    ## get global average\n",
    "    data_global_avg = src.utils.spatial_avg(data_djf)\n",
    "\n",
    "    ## combine into single dataset\n",
    "    data_prepped = xr.merge(\n",
    "        [data_trim.rename(\"slp\"), data_global_avg.rename(\"slp_global_avg\")]\n",
    "    )\n",
    "\n",
    "    return data_prepped\n",
    "\n",
    "\n",
    "def load_prepped_data(data_loader_fn, prep_fn, fp_out):\n",
    "    \"\"\"Function applies 'prep_fn' to data returned by 'data_loader_fn',\n",
    "    and saves result to 'fp_out'.\n",
    "    Args:\n",
    "        - data_loader_fn: function to load raw data\n",
    "        - prep_fn: function to pre-process raw data\n",
    "        - fp_out: filepath to save pre-processed data\n",
    "    \"\"\"\n",
    "\n",
    "    ## check if file exists\n",
    "    if os.path.isfile(fp_out):\n",
    "\n",
    "        ## Load pre-trimmed file\n",
    "        data_prepped = xr.open_dataset(fp_out).compute()\n",
    "\n",
    "    else:\n",
    "        ## Load data, trim it, and save to file\n",
    "        data = data_loader_fn()\n",
    "        data_prepped = prep_fn(data)\n",
    "        data_prepped.to_netcdf(fp_out)\n",
    "\n",
    "    return data_prepped\n",
    "\n",
    "\n",
    "def get_trimmed_data_lme(forcing_type, member_ids):\n",
    "    \"\"\"Process multiple ensemble members\"\"\"\n",
    "\n",
    "    ## Loop through each ensemble member\n",
    "    data_trimmed = []\n",
    "    for member_id in tqdm(member_ids):\n",
    "\n",
    "        ## get filepath for saving data\n",
    "        fp_out = f\"{DATA_FP}/LME_{forcing_type}_{member_id:03d}.nc\"\n",
    "\n",
    "        ## function to load the given ensemble member\n",
    "        data_loader_fn = lambda: load_lme_member(forcing_type, member_id)\n",
    "\n",
    "        ## load trimmed data\n",
    "        data_trimmed_i = load_prepped_data(data_loader_fn, trim, fp_out)\n",
    "\n",
    "        ## append result\n",
    "        data_trimmed.append(data_trimmed_i)\n",
    "\n",
    "    ## merge data from each ensemble member to single dataset\n",
    "    ensemble_member_dim = pd.Index(member_ids, name=\"ensemble_member\")\n",
    "    data_trimmed = xr.concat(data_trimmed, dim=ensemble_member_dim)\n",
    "\n",
    "    return data_trimmed\n",
    "\n",
    "\n",
    "def get_trimmed_data(data_loader_fn, fp_out):\n",
    "    return load_prepped_data(data_loader_fn=data_loader_fn, fp_out=fp_out, prep_fn=trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca82c0-cf85-4027-8651-883f1db95a02",
   "metadata": {},
   "source": [
    "#### Load in trimmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d2bcb-18bf-4e27-8d0e-34e6f60b27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_noaa = get_trimmed_data(data_loader_fn=load_noaa, fp_out=f\"{DATA_FP}/slp_noaa.nc\")\n",
    "slp_era = get_trimmed_data(data_loader_fn=load_era, fp_out=f\"{DATA_FP}/slp_era.nc\")\n",
    "slp_lme = get_trimmed_data_lme(forcing_type=\"all\", member_ids=np.arange(1, 14))\n",
    "slp_lme_volc = get_trimmed_data_lme(forcing_type=\"volcanic\", member_ids=np.arange(1, 6))\n",
    "slp_lme_GHG = get_trimmed_data_lme(forcing_type=\"GHG\", member_ids=np.arange(1, 4))\n",
    "slp_lme_orb = get_trimmed_data_lme(forcing_type=\"orbital\", member_ids=np.arange(1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26f044-848b-484b-a782-39003f27bb93",
   "metadata": {},
   "source": [
    "# Compute AHA metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1f1cc-1712-4d7b-a4fd-3da50b3f4cb0",
   "metadata": {},
   "source": [
    "From Cresswell-Clay et al. (2022): \"The AHA was defined as the area (km2) over the North Atlantic and Western Europe that had mean winter (December–January–February) SLP greater than 0.5 s.d. from the mean of the spatio-temporal winter SLP distribution (Fig. 1b). The region considered when calculating the AHA is bounded by the 60° W and 10° E meridians as well as the 10° N and 52° N latitudes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f7e10-e422-461d-843a-5de9b744a1da",
   "metadata": {},
   "source": [
    "#### Plot SLP over time in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a8048-7657-48f0-94e5-ef4ed9972c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify which dataset to use\n",
    "data = slp_noaa\n",
    "\n",
    "## Compute SLP averaged over Azores region\n",
    "slp_azores = src.utils.spatial_avg(src.utils_azores.trim_to_azores(data[\"slp\"]))\n",
    "slp_global = data[\"slp_global_avg\"]\n",
    "\n",
    "## get linear trend for global\n",
    "global_trend = src.utils.get_trend(slp_global)\n",
    "\n",
    "## Plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(data.year, slp_azores, label=\"Azores\")\n",
    "ax.plot(data.year, slp_global, label=\"Global\")\n",
    "ax.plot(data.year, global_trend, label=\"Global trend\", c=\"k\", ls=\"--\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"SLP (Pa)\")\n",
    "plt.show()\n",
    "\n",
    "## Plot before/after normalizing\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(\n",
    "    slp_noaa.year,\n",
    "    (slp_azores - slp_global + slp_global.mean()),\n",
    "    label=\"remove global mean\",\n",
    ")\n",
    "ax.plot(\n",
    "    data.year,\n",
    "    (slp_azores - global_trend + global_trend.mean()),\n",
    "    label=\"remove trend\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"SLP (Pa)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32599842-f855-44a2-a44f-77a9d805a58f",
   "metadata": {},
   "source": [
    "#### Fig 2c: # of AHA extremes since ~1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49112e69-e42b-4480-a6d7-6137107a3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count extremes in reanalysis\n",
    "count_noaa = src.utils_azores.count_extremes_wrapper(slp_noaa)\n",
    "count_era = src.utils_azores.count_extremes_wrapper(slp_era)\n",
    "\n",
    "## count in historical component of LME\n",
    "slp_lme_hist = slp_lme.sel(year=slice(1850, None))\n",
    "count_lme = src.utils_azores.count_extremes_wrapper(slp_lme_hist)\n",
    "\n",
    "## get ensemble mean, min, and max\n",
    "count_lme_mean = count_lme.mean(\"ensemble_member\")\n",
    "count_lme_min = count_lme.min(\"ensemble_member\")\n",
    "count_lme_max = count_lme.max(\"ensemble_member\")\n",
    "\n",
    "## make plot\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "## plot reanalysis\n",
    "ax.plot(count_noaa.year, count_noaa, label=\"NOAA\", c=\"purple\")\n",
    "ax.plot(count_era.year, count_era, label=\"ERA\", c=\"blue\")\n",
    "\n",
    "## plot LME mean and range\n",
    "count_lme_plot = ax.plot(count_lme.year, count_lme_mean, label=\"LME\", c=\"orange\")\n",
    "for bound in [count_lme_min, count_lme_max]:\n",
    "    ax.plot(bound.year, bound, c=count_lme_plot[0].get_color(), lw=0.5)\n",
    "\n",
    "## label plot\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Count (25-yr rolling)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb311e31-2b95-4826-b969-5d188bc9b951",
   "metadata": {},
   "source": [
    "### Fig. 3c,d: # of AHA extremes in LME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d3866-5e67-46af-84fb-300f94177f3e",
   "metadata": {},
   "source": [
    "#### Get ensemble stats of extreme count in LME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734f66f-81aa-4469-8841-f1855f969e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get extreme count\n",
    "def count_fn(data):\n",
    "    return src.utils_azores.count_extremes_wrapper(\n",
    "        data, norm_type=\"global_mean\", window=100\n",
    "    )\n",
    "\n",
    "\n",
    "# empty lists to hold results\n",
    "ensemble_mean = []\n",
    "ensemble_std = []\n",
    "\n",
    "# list of datasets and labels to process\n",
    "datasets = [slp_lme, slp_lme_GHG, slp_lme_volc, slp_lme_orb]\n",
    "labels = [\"Full\", \"GHG\", \"Volcanic\", \"Solar\"]\n",
    "\n",
    "## loop through datasets\n",
    "for data, label in zip(datasets, labels):\n",
    "\n",
    "    ## Count no. of extreme events\n",
    "    count = count_fn(data).rename(label)\n",
    "\n",
    "    ## get ensemble stats\n",
    "    ensemble_mean.append(count.mean(\"ensemble_member\"))\n",
    "    ensemble_std.append(count.std(\"ensemble_member\"))\n",
    "\n",
    "## combine into single dataset\n",
    "ensemble_mean = xr.merge(ensemble_mean)\n",
    "ensemble_std = xr.merge(ensemble_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63d6ba-1239-4111-a44a-bc61905b7cf3",
   "metadata": {},
   "source": [
    "#### Compare Azores High area in LME to paleo data\n",
    "Description of data here: https://www.ncei.noaa.gov/access/paleo-search/study/37160"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06c186-5e35-40fd-8362-a55e668420a5",
   "metadata": {},
   "source": [
    "Functions to load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c2040-d6b0-472c-be00-0f0b22e35640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paleo_data():\n",
    "    \"\"\"function to load Paleo data\"\"\"\n",
    "\n",
    "    ## data is located at following link:\n",
    "    fp = \"https://www.ncei.noaa.gov/pub/data/paleo/speleothem/europe/portugal/thatcher2022/thatcher2022-composite_isotope_records.txt\"\n",
    "\n",
    "    ## open dataset using Pandas\n",
    "    paleo_data = pd.read_csv(fp, skiprows=117, sep=r\"\\s+\").set_index(\"age_CE\")\n",
    "\n",
    "    ## convert to xarray and rename coordinate \"year\"\n",
    "    paleo_data = paleo_data.to_xarray().rename({\"age_CE\": \"year\"})\n",
    "\n",
    "    ## switch order of year coordinate so that it's increasing\n",
    "    paleo_data = paleo_data.reindex({\"year\": paleo_data.year.values[::-1]})\n",
    "\n",
    "    return paleo_data\n",
    "\n",
    "\n",
    "def compute_AHA_ensemble_mean(slp_data):\n",
    "    \"\"\"function to compute ensemble mean of AHA index\n",
    "    in LME with 'Full' forcing\"\"\"\n",
    "\n",
    "    ## compute AHA for each ensemble member\n",
    "    aha = src.utils_azores.compute_AHA(\n",
    "        slp=slp_data[\"slp\"],\n",
    "        slp_global_avg=slp_data[\"slp_global_avg\"],\n",
    "        norm_type=\"global_mean\",\n",
    "    )\n",
    "\n",
    "    ## compute ensemble mean\n",
    "    aha_ensemble_mean = aha.mean(\"ensemble_member\")\n",
    "\n",
    "    return aha_ensemble_mean\n",
    "\n",
    "\n",
    "def floor_nearest100(x):\n",
    "    \"\"\"rounds down to nearest 100\"\"\"\n",
    "\n",
    "    return np.floor(x / 100) * 100\n",
    "\n",
    "\n",
    "def bin_by_century(data, bin_offset=0):\n",
    "    \"\"\"\n",
    "    Function to bin data by century. Args:\n",
    "    - 'bin_offset' is number in [0, 100) representing\n",
    "        where the first bin begins.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get century to label data with\n",
    "    century = floor_nearest100(data[\"year\"] - bin_offset) + bin_offset\n",
    "\n",
    "    ## add century as new coordinate on data\n",
    "    ## (this makes it easy to group data by century)\n",
    "    data = data.assign_coords({\"century\": century.astype(int)})\n",
    "\n",
    "    # get mean for each century\n",
    "    data_binned = data.groupby(\"century\").mean()\n",
    "\n",
    "    return data_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7846e-5f01-4aed-9f5b-4a524e4f1d8b",
   "metadata": {},
   "source": [
    "Load the data and compute century-binned averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e323969c-af57-453b-badc-57f5a260d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "paleo_data = load_paleo_data()\n",
    "aha_mean = compute_AHA_ensemble_mean(slp_data=slp_lme)\n",
    "\n",
    "## Compute binned averages\n",
    "offset = 25  # the first bin begins at year (800 + offset)\n",
    "paleo_data_binned = bin_by_century(paleo_data, bin_offset=offset)\n",
    "aha_mean_binned = bin_by_century(aha_mean, bin_offset=offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9326ca-ade6-447e-8268-ca9046dfcb83",
   "metadata": {},
   "source": [
    "#### Plot results in style of paper\n",
    "Plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b4010-a3d5-461a-bc80-19a42b96fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_LME_extremes(ax):\n",
    "    \"\"\"function to plot LME extremes on ax object\"\"\"\n",
    "\n",
    "    ## specify colors and linestyles for each LME run\n",
    "    labels = [\"Full\", \"GHG\", \"Volcanic\", \"Solar\"]\n",
    "    colors = [\"k\", \"green\", \"red\", \"orange\"]\n",
    "    scales = [1, 0.75, 0.5, 0.5]\n",
    "\n",
    "    ## Plot lines one-by-one\n",
    "    for label, color, scale in zip(labels, colors, scales):\n",
    "\n",
    "        ## get linewidth based on scale\n",
    "        mean_width = 2.0 * scale\n",
    "        range_width = 0.5 * scale\n",
    "\n",
    "        ## plot ensemble mean\n",
    "        ax.plot(\n",
    "            ensemble_mean.year,\n",
    "            ensemble_mean[label],\n",
    "            label=label,\n",
    "            c=color,\n",
    "            lw=mean_width,\n",
    "        )\n",
    "\n",
    "    ## plot standard deviation for \"Full\" run\n",
    "    upper_bound = ensemble_mean[\"Full\"] + ensemble_std[\"Full\"]\n",
    "    lower_bound = ensemble_mean[\"Full\"] - ensemble_std[\"Full\"]\n",
    "    ax.fill_between(ensemble_mean.year, upper_bound, lower_bound, color=\"k\", alpha=0.07)\n",
    "\n",
    "    ## label plot\n",
    "    ax.legend(prop={\"size\": 8})\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Extreme events\")\n",
    "    ax.set_yticks([5, 10, 15])\n",
    "    ax.set_ylim([None, 17.5])\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_paleo_comparison(ax):\n",
    "    \"\"\"function to plot paleo data and AHA over time\"\"\"\n",
    "\n",
    "    ## plot paleo data first\n",
    "    paleo_plot = ax.plot(\n",
    "        paleo_data_binned.century + 50, paleo_data_binned[\"d13C_compSuess\"]\n",
    "    )\n",
    "    ax.set_ylabel(r\"$\\delta^{13}C$\", c=paleo_plot[0].get_color())\n",
    "    ax.set_yticks([-1, -2, -3], labels=[-1, -2, -3], color=paleo_plot[0].get_color())\n",
    "    ax.set_xlim([825, 2025])\n",
    "\n",
    "    ## plot AHA on same x-axis\n",
    "    ax1 = ax.twinx()\n",
    "    ax1.plot(aha_mean_binned.century + 50, aha_mean_binned, c=\"k\")\n",
    "    ax1.set_ylabel(r\"Azores area ($km^2$)\")\n",
    "    ax1.set_yticks([1e7, 1.1e7, 1.2e7])\n",
    "\n",
    "    return ax, ax1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480b976-9da0-4742-a788-869e6e505b4c",
   "metadata": {},
   "source": [
    "Make plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c725f-798d-4cd5-bf81-a287935fc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "gs = mpl.gridspec.GridSpec(2, 1, height_ratios=[0.7, 1])\n",
    "\n",
    "## plot binned paleo data and AHA over time\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax00, ax01 = plot_paleo_comparison(ax0)\n",
    "ax00.set_xticks([])\n",
    "\n",
    "## Plot extreme count over time\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax1 = plot_LME_extremes(ax1)\n",
    "\n",
    "## make sure x-axes match\n",
    "ax1.set_xlim(ax0.get_xlim())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67501502-1023-470e-ae80-135a80c4b67d",
   "metadata": {},
   "source": [
    "# Spatial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad0647-8838-4178-8ee9-c2ffbb184385",
   "metadata": {},
   "source": [
    "#### Functions to compute and plot composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe5754-4964-4e37-b6b3-51609b317fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_composite(data, year_range0=[1950, 1979], year_range1=[1980, 2007]):\n",
    "    \"\"\"get composite, defined as difference between data\n",
    "    when averaged over year_range1 and year_range0.\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute means\n",
    "    mean1 = data.sel(year=slice(*year_range1)).mean(\"year\")\n",
    "    mean0 = data.sel(year=slice(*year_range0)).mean(\"year\")\n",
    "\n",
    "    return mean1 - mean0\n",
    "\n",
    "\n",
    "def plot_setup_helper(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-70, 10]\n",
    "    lat_range = [3, 70]\n",
    "    xticks = [-60, -40, -20, 0]\n",
    "    yticks = [20, 40, 60]\n",
    "\n",
    "    ax, gl = src.utils.plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88f06a-5c78-4c46-8d92-0bbb02e6db60",
   "metadata": {},
   "source": [
    "#### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c09e1-58c0-46a2-870b-cbeec83d41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noaa_uv10():\n",
    "    \"\"\"Load NOAA U10 and V10 data (eastward and northward windspeed at 10m)\"\"\"\n",
    "\n",
    "    ## load raw files for u and v\n",
    "    fp = \"/mnt/cmip5-data/reanalysis/noaa.cires.20crv2c/gaussian\"\n",
    "    u10_noaa = xr.open_dataset(f\"{fp}/uwnd.10m/monthly/uwnd.10m.mon.mean.nc\")\n",
    "    v10_noaa = xr.open_dataset(f\"{fp}/vwnd.10m/monthly/vwnd.10m.mon.mean.nc\")\n",
    "\n",
    "    ## merge into single dataset\n",
    "    uv10_noaa = xr.merge([u10_noaa, v10_noaa])\n",
    "\n",
    "    return uv10_noaa\n",
    "\n",
    "\n",
    "def load_noaa_precip():\n",
    "    \"\"\"Load NOAA precipitation data from CMIP server.\n",
    "    Returns xr.dataarray with units of mm\"\"\"\n",
    "\n",
    "    ## load in precipitation rate (units: kg/m^2/s)\n",
    "    fp = \"/mnt/cmip5-data/reanalysis/noaa.cires.20crv2c/gaussian/prate/monthly/prate.mon.mean.nc\"\n",
    "    precip_rate = xr.open_dataset(fp)[\"prate\"]\n",
    "\n",
    "    ## change units to mm (millimeters)\n",
    "    precip = update_precip_units(precip_rate).rename(\"precip\")\n",
    "\n",
    "    return precip\n",
    "\n",
    "\n",
    "def update_precip_units(precip_rate):\n",
    "    \"\"\"change units of precipitation from (kg m^-2 s^-1) to mm\n",
    "    by dividing by density of water and integrating in time\"\"\"\n",
    "\n",
    "    ## Convert units from mass/area to height by dividing\n",
    "    ## by density of liquid water:\n",
    "    ## (km m^-2 s^-1) * (kg^-1 m^3) = m s^-1\n",
    "    density_water = 1000  # units: kg m^-3\n",
    "    precip_rate = precip_rate / density_water  # new units of m/s\n",
    "\n",
    "    ## convert from month-averaged rate (units: m/s) to\n",
    "    ## month total (units: m), by multiplyin by no. of seconds\n",
    "    ## in each month. Units: (m s^-1) * s = m.\n",
    "    ## Note: days_per_month depends on month (so is\n",
    "    ## array, not a scalar, in the code below).\n",
    "    days_per_month = precip_rate.time.dt.days_in_month\n",
    "    seconds_per_day = 86400\n",
    "    seconds_per_month = seconds_per_day * days_per_month\n",
    "    precip = precip_rate * seconds_per_month\n",
    "\n",
    "    ## convert units from m to mm\n",
    "    mm_per_m = 1000\n",
    "    precip = precip * mm_per_m\n",
    "\n",
    "    return precip\n",
    "\n",
    "\n",
    "def load_noaa_lsm():\n",
    "    \"\"\"Load NOAA land-sea mask for NOAA reanalysis\"\"\"\n",
    "\n",
    "    ## load raw data\n",
    "    url = \"http://psl.noaa.gov/thredds/dodsC/Datasets/20thC_ReanV2c/gaussian/time_invariant/land.nc\"\n",
    "    lsm = xr.open_dataset(url).isel(time=0, drop=True).compute()\n",
    "\n",
    "    ## remove this attribute: causes issues with saving to netcdf\n",
    "    del lsm.attrs[\"_NCProperties\"]\n",
    "\n",
    "    return lsm\n",
    "\n",
    "\n",
    "def update_coords_noaa(data):\n",
    "    \"\"\"function to update coordinates of NOAA data\"\"\"\n",
    "\n",
    "    data = src.utils.switch_longitude_range(data)\n",
    "    data = src.utils.reverse_latitude(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def trim_noaa(data, djf_avg=True):\n",
    "    \"\"\"function to trim non-SLP NOAA data\"\"\"\n",
    "\n",
    "    ## update coordinates before trimming\n",
    "    data = update_coords_noaa(data)\n",
    "\n",
    "    ## Get DJF average if variable is a function of time\n",
    "    if \"time\" in data.coords:\n",
    "        data = src.utils.djf_avg(data).compute()\n",
    "\n",
    "    ## trim in space\n",
    "    data = src.utils_azores.trim_to_north_atlantic(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_trimmed_data_noaa(data_loader_fn, fp_out):\n",
    "    return load_prepped_data(\n",
    "        data_loader_fn=data_loader_fn, prep_fn=trim_noaa, fp_out=fp_out\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4f8d3-c02a-4ba7-af92-37db0ab98fdb",
   "metadata": {},
   "source": [
    "#### Do the actual data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7517ff-6bf2-4862-a269-eb75d895fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv10_noaa = get_trimmed_data_noaa(load_noaa_uv10, fp_out=f\"{DATA_FP}/uv10_noaa.nc\")\n",
    "precip_noaa = get_trimmed_data_noaa(\n",
    "    load_noaa_precip, fp_out=f\"{DATA_FP}/precip_noaa.nc\"\n",
    ")\n",
    "lsm_noaa = get_trimmed_data_noaa(load_noaa_lsm, fp_out=f\"{DATA_FP}/lsm_noaa.nc\")\n",
    "\n",
    "## update grid of SLP so we can compare it to other variables\n",
    "regridder = xe.Regridder(ds_in=slp_noaa, ds_out=lsm_noaa, method=\"bilinear\")\n",
    "slp_noaa_regrid = regridder(slp_noaa)\n",
    "\n",
    "## merge variables into single dataset\n",
    "data_noaa = xr.merge([slp_noaa_regrid, uv10_noaa, precip_noaa])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130a5cf-061b-40df-a2d0-325c8677d99e",
   "metadata": {},
   "source": [
    "#### Compute composite and climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2b546-746f-4eea-b4f4-ab1bff6a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute composite and climatology\n",
    "comp = make_composite(data_noaa)\n",
    "clim = data_noaa.sel(year=slice(1950, 2007)).mean(\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74519b-8f4c-483c-bf54-20d388f9122c",
   "metadata": {},
   "source": [
    "#### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb70763-db96-4e5c-9e91-7e9ec99e89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to plot individual variables on plotting background.\n",
    "## these functions take in an 'ax' object\n",
    "def plot_precip(fig, ax):\n",
    "    \"\"\"plot precipitation composite\"\"\"\n",
    "\n",
    "    ## plot data\n",
    "    precip_plot = ax.contourf(\n",
    "        comp.lon,\n",
    "        comp.lat,\n",
    "        comp[\"precip\"],\n",
    "        cmap=\"cmo.diff_r\",\n",
    "        levels=src.utils.make_cb_range(35, 3.5),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## add colorbar\n",
    "    precip_cb = fig.colorbar(\n",
    "        precip_plot,\n",
    "        pad=0.05,\n",
    "        ax=ax,\n",
    "        orientation=\"horizontal\",\n",
    "        label=r\"$\\Delta$ Precip. (mm/month)\",\n",
    "        ticks=np.arange(-28, 42, 14),\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_slp(fig, ax, mask=False, add_colorbar=False):\n",
    "    \"\"\"Plot SLP. If mask==True, mask values over land\"\"\"\n",
    "\n",
    "    ## mask data if specified\n",
    "    if mask:\n",
    "        plot_data = comp[\"slp\"].where(lsm_noaa[\"land\"] < 1)\n",
    "    else:\n",
    "        plot_data = comp[\"slp\"]\n",
    "\n",
    "    slp_plot = ax.contourf(\n",
    "        comp.lon,\n",
    "        comp.lat,\n",
    "        plot_data,\n",
    "        cmap=\"cmo.balance\",\n",
    "        levels=src.utils.make_cb_range(500, 50),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    ## add colorbar if desired\n",
    "    if add_colorbar:\n",
    "        slp_cb = fig.colorbar(\n",
    "            slp_plot,\n",
    "            ax=ax,\n",
    "            pad=0.05,\n",
    "            orientation=\"horizontal\",\n",
    "            label=r\"$\\Delta$ SLP (Pa)\",\n",
    "            ticks=np.arange(-400, 600, 200),\n",
    "        )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_slp_clim(fig, ax):\n",
    "    \"\"\"Plot SLP. If mask==True, mask values over land\"\"\"\n",
    "\n",
    "    slp_plot_clim = ax.contour(\n",
    "        clim.lon,\n",
    "        clim.lat,\n",
    "        clim[\"slp\"],\n",
    "        colors=\"k\",\n",
    "        levels=np.arange(99600, 102400, 400),\n",
    "        linewidths=0.8,\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_wind(fig, ax, n=3):\n",
    "    \"\"\"Plot low-level wind. Plot every 'n'th vector to avoid overcrowding\"\"\"\n",
    "\n",
    "    # get grid for plotting\n",
    "    xx, yy = np.meshgrid(comp.lon.values[::n], comp.lat.values[::n])\n",
    "\n",
    "    # plot the vectors\n",
    "    wind_plot = ax.quiver(\n",
    "        xx, yy, comp[\"uwnd\"].values[::n, ::n], comp[\"vwnd\"].values[::n, ::n]\n",
    "    )\n",
    "\n",
    "    # add legend\n",
    "    wind_legend = ax.quiverkey(wind_plot, X=1.07, Y=-0.28, U=2, label=r\"2 $m/s$\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d61b1d-f6fa-447d-9b11-bd9f73ec77cb",
   "metadata": {},
   "source": [
    "#### Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8c040-f93b-4120-a527-aa4dbdfe56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create figure\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "## add first plotting background\n",
    "ax0 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "ax0, gl0 = plot_setup_helper(ax0, scale=1.2)\n",
    "\n",
    "## plot precip in colors over land:\n",
    "plot_precip(fig, ax0)\n",
    "plot_slp(fig, ax0, mask=True)\n",
    "plot_wind(fig, ax0, n=3)\n",
    "\n",
    "## add second plotting background, and remove left longitude labels\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "ax1, gl1 = plot_setup_helper(ax1, scale=1.2)\n",
    "gl1.left_labels = False\n",
    "\n",
    "## for SLP: plot composite in colors and climatology in contours\n",
    "plot_slp(fig, ax1, add_colorbar=True)\n",
    "plot_slp_clim(fig, ax1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
