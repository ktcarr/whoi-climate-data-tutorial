{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48560c47-b4db-476f-83e3-a28d73ff06f7",
   "metadata": {},
   "source": [
    "# Overview: model validation\n",
    "\n",
    "The goal of this tutorial is to provide an example of model validation using data on WHOI's CMIP servers. By \"model validation\", we mean checking that a given climate model represents the key features of a process or region in a reasonable way. To perform this check, we compare the model's statistics to that of observations or reanalysis for an overlapping period (e.g., the period 1950-present). When doing a climate change analysis, the purpose of this validation is to provide confidence that we can trust the model's *future* projections for the process/region of interest (for which we don't have any observations to compare it to). For example, if we're interested in using a model to estimate future temperature changes in Woods Hole, we might want to start by checking whether the model accurately represents the mean and standard deviation of temperature in Woods Hole. Examples of more \"advanced\" features to compare between the model and observations might include the mean position of the Jet Stream, which impacts weather in Woods Hole, or the correlation between Woods Hole temperature and El Ni√±o events.\n",
    "\n",
    "In this tutorial, we'll go through an abbreviated version of this example, comparing Woods Hole temperature variability between a reanalysis product (ERA5) and a global climate model (CESM2). We'll also look at an oceanic example where the model does an arguably worse job of representing the most relevant physical processes: motivated by the question \"will the Gulf Stream shift north with climate change?\", we'll assess the CESM2 model's representation of Gulf Stream position.\n",
    "\n",
    "[__Your task:__ Evaluate a climate model's ability to represent your climate index](#To-do:-validate-a-climate-model). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e46e9-4214-490f-b866-f3aa9977b889",
   "metadata": {},
   "source": [
    "## Check if we're running in Google Colab\n",
    "If you are running in Google Colab, you may have to run the cell below twice because the kernel crashes; I'm not sure why this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e04bd-86d2-4d2e-a0e6-2bad9e4c9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    ## install package that allows us to use mamba in Colab\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "\n",
    "    condacolab.install()\n",
    "\n",
    "    ## install extra packages to colab environment\n",
    "    !mamba install -c conda-forge python=3.10.13 cmocean xesmf cartopy cftime cartopy\n",
    "\n",
    "    ## connect to Google Drive (will prompt you to ask for permissions)\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    ## flag telling us the notebook is running in Colab\n",
    "    IN_COLAB = True\n",
    "\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca03ff-96f9-4499-b942-84e0ec9560dc",
   "metadata": {},
   "source": [
    "## Filepaths\n",
    "__To run this notebook, you'll need to update the filepaths below__, which specify the location of the data (otherwise, you'll get a ```FileNotFoundError``` message when you try to open the data). These filepaths will differ for Mac vs. Windows users and depend on how you've accessed the data (e.g., mounting the WHOI file server or downloading the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cba96-487c-4e15-858e-d0b62bb053ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "\n",
    "    ## filepaths for 2m-Temperature data\n",
    "    era5_t2m_path = \"/content/drive/My Drive/climate-data/era5/2m_temperature\"\n",
    "    cesm_t2m_path = \"/content/drive/My Drive/climate-data\"\n",
    "\n",
    "    ## filepaths for SSH data\n",
    "    oras_path = \"/content/drive/My Drive/climate-data/oras\"\n",
    "    cesm_zos_path = \"/content/drive/My Drive/climate-data\"\n",
    "\n",
    "else:\n",
    "\n",
    "    ## filepaths for 2m-temperature data\n",
    "    era5_t2m_path = (\n",
    "        \"/Volumes/cmip6/data/era5/reanalysis/single-levels/monthly-means/2m_temperature\"\n",
    "    )\n",
    "    cesm_t2m_path = (\n",
    "        \"/Volumes/cmip6/data/cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1/Amon/tas/gn/1\"\n",
    "    )\n",
    "\n",
    "    ## filepaths for SSH data\n",
    "    oras_path = \"/Volumes/cmip6/data/ocean_reanalysis/ORAS5/oras5/monthly/global-reanalysis-phy-001-031\"\n",
    "    cesm_zos_path = (\n",
    "        \"/Volumes/cmip6/data/cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1/Omon/zos/gn/1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d5291-16ce-48b3-8272-bcf30027d87e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22e30b-8dc2-447c-b7b7-e0732af6b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cftime\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b651d4-3447-44fc-bd6c-a11066ab8ca4",
   "metadata": {},
   "source": [
    "## Example 1/2: Woods Hole temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97e4ab-199c-43be-b5fb-f142b32ffd6e",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b191e565-2e7f-4bec-8dbc-5a8997739c3d",
   "metadata": {},
   "source": [
    "First, a function to trim the data to the North Atlantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a2636-0cad-4571-982d-cb1a7a026c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to subset longitude/latitude\n",
    "def trim_to_north_atl(x):\n",
    "    \"\"\"trims data to the North Pacific region\"\"\"\n",
    "\n",
    "    ## lon/lat boundaries for region to subset\n",
    "    lon_range = [258.5, 318.5]\n",
    "    lat_range = [60, 20]\n",
    "    # latitude=41.5, longitude=288.5\n",
    "\n",
    "    ## trim the data\n",
    "    x_trimmed = x.sel(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
    "\n",
    "    return x_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7fc6c5-ee7e-450f-9a2a-6d9522ac6988",
   "metadata": {},
   "source": [
    "Load in ERA5 reanalysis data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc5456-fae6-4446-9e47-ab26462b1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of files in the folder\n",
    "file_list = glob.glob(os.path.join(era5_t2m_path, \"*.nc\"))\n",
    "\n",
    "## Load in the data\n",
    "T2m_era = xr.open_mfdataset(file_list, preprocess=trim_to_north_atl)[\"t2m\"]\n",
    "T2m_era = T2m_era.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937fe901-6bd1-422a-b353-4d4679b6f40e",
   "metadata": {},
   "source": [
    "Load in CESM2 data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7cbb3-cd04-4c8b-b948-06c286ccd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cesm_fname = \"tas_Amon_CESM2_historical_r1i1p1f1_gn_185001-201412.nc\"\n",
    "T2m_cesm = xr.open_dataset(os.path.join(cesm_t2m_path, cesm_fname))[\"tas\"]\n",
    "\n",
    "## rename lon/lat to match ERA5\n",
    "T2m_cesm = T2m_cesm.rename({\"lon\": \"longitude\", \"lat\": \"latitude\"})\n",
    "\n",
    "## reverse latitude coordinate, so that it matches ERA5\n",
    "latitude_reversed = T2m_cesm.latitude.values[::-1]\n",
    "T2m_cesm = T2m_cesm.reindex({\"latitude\": latitude_reversed})\n",
    "\n",
    "## trim to N. Atlantic\n",
    "T2m_cesm = trim_to_north_atl(T2m_cesm)\n",
    "\n",
    "## load to memory\n",
    "T2m_cesm.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c4500-79d5-4079-8aed-7638b087a590",
   "metadata": {},
   "source": [
    "Trim both datasets to overlapping period (1979-2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821421e6-ce48-477c-9346-2b4709536599",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2m_era = T2m_era.sel(time=slice(None, \"2014\"))\n",
    "T2m_cesm = T2m_cesm.sel(time=slice(\"1979\", None))\n",
    "\n",
    "## for convenience, set T2m_cesm's time to match T2m_era\n",
    "T2m_cesm[\"time\"] = T2m_era.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69c5a0-ad4c-44e0-86de-2c0cc0177191",
   "metadata": {},
   "source": [
    "### Plot climatology (mean state)\n",
    "As a first step, let's plot the mean state in the reanalysis and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02579272-fe1d-4c9f-ab9a-2515fac1f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, a generic plot setup function\n",
    "def plot_setup(ax, lon_range, lat_range, xticks, yticks, scale):\n",
    "    \"\"\"\n",
    "    Create map background for plotting spatial data.\n",
    "    Arguments:\n",
    "        - ax: Matplotlib object containing everything in the plot.\n",
    "            (I think of it as the plot \"canvas\")\n",
    "        - lon_range/lat_range: 2-element arrays, representing plot boundaries\n",
    "        - xticks/yticks: location for lon/lat labels\n",
    "        - scale: number which controls linewidth and fontsize\n",
    "\n",
    "    Returns a modified 'ax' object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## specify transparency/linewidths\n",
    "    grid_alpha = 0.1 * scale\n",
    "    grid_linewidth = 0.5 * scale\n",
    "    coastline_linewidth = 0.3 * scale\n",
    "    label_size = 8 * scale\n",
    "\n",
    "    ## crop map and plot coastlines\n",
    "    ax.set_extent([*lon_range, *lat_range], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=coastline_linewidth)\n",
    "\n",
    "    ## plot grid\n",
    "    gl = ax.gridlines(\n",
    "        draw_labels=True,\n",
    "        linestyle=\"--\",\n",
    "        alpha=grid_alpha,\n",
    "        linewidth=grid_linewidth,\n",
    "        color=\"k\",\n",
    "        zorder=1.05,\n",
    "    )\n",
    "\n",
    "    ## add tick labels\n",
    "    gl.bottom_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": label_size}\n",
    "    gl.ylabel_style = {\"size\": label_size}\n",
    "    gl.ylocator = mticker.FixedLocator(yticks)\n",
    "    gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax, gl\n",
    "\n",
    "\n",
    "## Next, a function to plot the North Atlantic\n",
    "def plot_setup_north_atl(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-102.5, -42.5]\n",
    "    lat_range = [60, 20]\n",
    "    xticks = [-90, -75, -60]\n",
    "    yticks = [25, 40, 55]\n",
    "\n",
    "    ax, gl = plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl\n",
    "\n",
    "\n",
    "## utility function to make levels for colorbar\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f7753-f8ac-4bf6-8b0e-e76cf2969f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify colorbar levels\n",
    "levels = np.arange(266, 306, 4)\n",
    "\n",
    "## make plot\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "for i, (data, label) in enumerate(zip([T2m_era, T2m_cesm], [\"ERA5\", \"CESM2\"]), start=1):\n",
    "\n",
    "    ## ERA\n",
    "    ax = fig.add_subplot(1, 2, i, projection=ccrs.PlateCarree())\n",
    "    ax, gl = plot_setup_north_atl(ax)\n",
    "    ax.set_title(f\"{label}\")\n",
    "\n",
    "    ## plot data\n",
    "    plot = ax.contourf(\n",
    "        data.longitude,\n",
    "        data.latitude,\n",
    "        data.mean(\"time\"),\n",
    "        cmap=\"cmo.thermal\",\n",
    "        levels=levels,\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e554dca-0766-4207-bcbb-2104a7dabb0b",
   "metadata": {},
   "source": [
    "### Plot bias\n",
    "To compare temperature at the grid-point level, let's interpolate the reanalysis onto the model's longitude/latitude grid. To compute the mean bias, subtract the reanalysis mean from the model mean. We'll also compute the \"bias\" in standard deviations by subtracting the reanalysis' standard deivation from that of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7dd4f-c41a-4d29-82b1-d74fd8e0b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regrid ERA5 and look at difference\n",
    "T2m_era_regrid = T2m_era.interp(\n",
    "    {\"latitude\": T2m_cesm.latitude, \"longitude\": T2m_cesm.longitude}\n",
    ")\n",
    "\n",
    "## get difference between means\n",
    "bias = T2m_cesm.mean(\"time\") - T2m_era_regrid.mean(\"time\")\n",
    "\n",
    "## get difference between std. devs.\n",
    "bias_std = T2m_cesm.std(\"time\") - T2m_era_regrid.std(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13ec05-b0dc-4d1c-a2ff-eda5b889331d",
   "metadata": {},
   "source": [
    "Next, plot the difference between the means. Note the huge bias off the coast of the northeast U.S.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e345422-c421-435b-b162-1e0a35631072",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make plot\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "ax.set_title(r\"$\\mu$ bias (ERA5 ‚Äì CESM2)\")\n",
    "\n",
    "## plot data\n",
    "plot = ax.contourf(\n",
    "    bias.longitude,\n",
    "    bias.latitude,\n",
    "    bias,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=make_cb_range(5, 0.5),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb = fig.colorbar(plot, ticks=[-5, 0, 5], label=r\"$T_{2m}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb0167-9e5e-4bcd-8265-f5f6519c2623",
   "metadata": {},
   "source": [
    "Plot difference b/n standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ec744-55f0-461a-8e64-aba1cb7fcc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make plot\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "ax.set_title(r\"$\\sigma$ bias (ERA5 ‚Äì CESM2)\")\n",
    "\n",
    "## plot data\n",
    "plot = ax.contourf(\n",
    "    bias_std.longitude,\n",
    "    bias_std.latitude,\n",
    "    bias_std,\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=make_cb_range(5, 0.5),\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "cb = fig.colorbar(plot, ticks=[-5, 0, 5], label=r\"$T_{2m}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1b6fd-3e98-4b0b-8f85-a09868081c17",
   "metadata": {},
   "source": [
    "### Get $T_{2m}$ near Woods Hole\n",
    "Next, we'll look at the model's representation of temperature variability in Woods Hole. To do this, we'll estimate Woods Hole temperature by interpolating from the closest grid cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cb593-c498-42db-97e1-dec614835acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2m_era_wh = T2m_era.interp(latitude=41.5, longitude=288.5)\n",
    "T2m_cesm_wh = T2m_cesm.interp(latitude=41.5, longitude=288.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263b931-e2d5-4ee6-a162-cd75f65e4801",
   "metadata": {},
   "source": [
    "### Plot seasonal cycle\n",
    "Let's check how the model represents the seasonal cycle of temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1170f-6e94-416f-af7c-60fa93ace4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clim(ax, x, label):\n",
    "    \"\"\"plot seasonal cycle and standard deviation for variable\"\"\"\n",
    "\n",
    "    ## compute stats\n",
    "    mean = x.groupby(\"time.month\").mean()\n",
    "    std = x.groupby(\"time.month\").std()\n",
    "\n",
    "    ## plot them\n",
    "    mean_plot = ax.plot(mean.month, mean, label=label)\n",
    "\n",
    "    ## specify style of bounds:\n",
    "    ax.fill_between(\n",
    "        mean.month, mean + std, mean - std, color=mean_plot[0].get_color(), alpha=0.2\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax = plot_clim(ax, T2m_era_wh, label=\"ERA5\")\n",
    "ax = plot_clim(ax, T2m_cesm_wh, label=\"CESM2\")\n",
    "ax.legend()\n",
    "ax.set_xticks([3, 6, 9, 12], labels=[\"Mar\", \"Jun\", \"Sep\", \"Dec\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b755ecb-9422-499f-a613-62cc84abd1f3",
   "metadata": {},
   "source": [
    "### Plot histograms\n",
    "So far, we've quantified \"variability\" by computing the mean and standard deviation. These metrics completely describe the shape of a Gaussian (or \"normal\") distribution, but the statistics may not be Gaussian (one *non*-normal example is the probability distribution for daily precipitation). To check for differences in the shape of the $T_{2m}$ distribution (e.g., does the reanalysis distribution have wider \"tails\"?), let's compare histograms of Woods Hole temperature between the reanalysis and model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3770ff-cde7-4da6-869c-4717f4789329",
   "metadata": {},
   "source": [
    "Because we care about deviations from the mean in this case, let's remove the mean and trend from the timeseries in both reanalysis and observations. We'll do this by grouping the data by month, and removing a linear trend from each group (so that we compute separate trends for Jan, Feb, ..., Dec). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7c7f6-aeeb-49e8-bda3-424944ba75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(data, dim=\"time\"):\n",
    "    \"\"\"Get linear trend for an xr.dataarray along specified dimension\"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=1)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\"):\n",
    "    \"\"\"remove linear trend along specified dimension\"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=\"time\")\n",
    "\n",
    "\n",
    "def detrend_by_month(data):\n",
    "    \"\"\"function detrends data for each month separately\"\"\"\n",
    "    return data.groupby(\"time.month\").map(detrend)\n",
    "\n",
    "\n",
    "## detrend each time series by month\n",
    "T2m_era_wh_detrend = detrend_by_month(T2m_era_wh)\n",
    "T2m_cesm_wh_detrend = detrend_by_month(T2m_cesm_wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142676b9-020c-41b6-a104-a70792c23c61",
   "metadata": {},
   "source": [
    "Next, plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dfc0e-c889-4768-9c86-9b065b006fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_comparison(ax, samples0, samples1, label0=None, label1=None):\n",
    "    \"\"\"\n",
    "    Compute two histograms, one each for samples0 and samples1.\n",
    "    Plot the results on the specified ax object, and label histograms\n",
    "    'label0' and 'label1', respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    ## First, make the histograms.\n",
    "    # specify histogram bins\n",
    "    bin_width = 0.5\n",
    "    bin_edges = np.arange(-5.25, 5.25 + bin_width, bin_width)\n",
    "\n",
    "    # compute histograms\n",
    "    hist0, _ = np.histogram(samples0, bins=bin_edges)\n",
    "    hist1, _ = np.histogram(samples1, bins=bin_edges)\n",
    "\n",
    "    ## plot histograms\n",
    "    ax.stairs(values=hist0, edges=bin_edges, color=\"k\", label=label0)\n",
    "    ax.stairs(\n",
    "        values=hist1,\n",
    "        edges=bin_edges,\n",
    "        color=\"k\",\n",
    "        label=label1,\n",
    "        fill=True,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ## label plot\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(r\"$T_{2m}$ anomaly ($^{\\circ}C$)\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56448ddc-0d60-4e43-a0a7-8588a4a241d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 3))\n",
    "ax = fig.add_subplot()\n",
    "ax = plot_histogram_comparison(\n",
    "    ax, T2m_era_wh_detrend, T2m_cesm_wh_detrend, label0=\"ERA5\", label1=\"CESM2\"\n",
    ")\n",
    "ax.axvline(0, ls=\":\", c=\"w\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2a13b-6a61-4fbe-81cb-9f718abc014c",
   "metadata": {},
   "source": [
    "## Example 2/2: Gulf Stream position\n",
    "In this example, we'll assess the CESM2 model's representation of Gulf Stream position, motivated by an interest in determining whether the Gulf Stream position will shift in a warmer climate$^{1,2}$. To do this, we'll compare the CESM2 model to the ORAS5 reanalysis product. We'll look at each data product's representation of sea surface height (SSH) gradients in the North Atlantic, a proxy for Gulf Stream transport. Loosely speaking, the Gulf Stream follows contours of SSH, with equal volume transport between contours (so that the velocity is larger between tightly-packed contours). The gradient of SSH measures how tightly packed the contours are, so we can think of the gradient as a proxy for Gulf Stream strength.\n",
    "\n",
    "$^{1}$Todd, R. E. & Ren, A. S. Warming and lateral shift of the Gulf Stream from in situ observations since 2001. Nat. Clim. Chang. 13, 1348‚Äì1352 (2023).  \n",
    "$^{2}$Yang, H. et al. Poleward Shift of the Major Ocean Gyres Detected in a Warming Climate. Geophysical Research Letters 47, (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f045c66-5120-4315-b522-656bd82bcf15",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de602fd-7209-4fc6-b9e0-8d0d3ed44bc7",
   "metadata": {},
   "source": [
    "Load ORAS5 reanalysis data. Note that we're extracting a variable abbreviated ```zos_oras```, the \"sea surface height above geoid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704b190-735e-4dff-9972-d0984d1aef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oras_file_pattern = os.path.join(\n",
    "    oras_path, \"global-reanalysis-phy-001-031-grepv2-monthly_*.nc\"\n",
    ")\n",
    "zos_oras = xr.open_mfdataset(oras_file_pattern)\n",
    "zos_oras = zos_oras[\"zos_oras\"]\n",
    "zos_oras.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa3ba-d463-47c0-9921-0ee83266976c",
   "metadata": {},
   "source": [
    "Load in CESM2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9499ca-c7f0-4fc0-b6a6-31930b090494",
   "metadata": {},
   "outputs": [],
   "source": [
    "cesm_zos_filename = os.path.join(\n",
    "    cesm_zos_path, \"zos_Omon_CESM2_historical_r1i1p1f1_gn_185001-201412.nc\"\n",
    ")\n",
    "zos_cesm = xr.open_dataset(cesm_zos_filename)\n",
    "zos_cesm = zos_cesm[\"zos\"]\n",
    "zos_cesm = zos_cesm.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4930ab-d4f3-4b49-8ba9-5c87312502c1",
   "metadata": {},
   "source": [
    "### Regrid CESM to match ORAS5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4557f1-5c60-4f4a-bbf0-09511c69297e",
   "metadata": {},
   "source": [
    "We'll use the xesmf package for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57229217-e2a4-4960-8a0f-56bcda6f3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be727a58-fc79-4325-8781-97af8ea936d9",
   "metadata": {},
   "source": [
    "For ease of comparison, let's regrid the CESM2 data to match ORAS5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280d27c-1cfd-4ca3-b148-7701aca34312",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(\n",
    "    ds_in=zos_cesm, ds_out=zos_oras, method=\"bilinear\", periodic=False\n",
    ")\n",
    "zos_cesm = regridder(zos_cesm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35752c07-f122-4e46-bebe-03f46563b05b",
   "metadata": {},
   "source": [
    "Try using CDO if ```xesmf``` doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a2cf7-a457-4995-9f6e-a0d303713221",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify \"target\" grid\n",
    "target_grid = zos_oras.isel(time=0, drop=True)\n",
    "target_grid.to_netcdf(\"target_grid.nc\")\n",
    "\n",
    "## Get text file description of the grid (needed for regridding)\n",
    "!cdo griddes target_grid.nc > target_grid.txt\n",
    "\n",
    "## Do the regridding with CDO\n",
    "!cdo -O remapbil,target_grid.txt {cesm_zos_filename} zos_cesm_regridded.nc\n",
    "\n",
    "## remove temporary files\n",
    "!rm target_grid.txt target_grid.nc\n",
    "\n",
    "## Load in regridded data\n",
    "zos_cesm = xr.open_dataset(\"zos_cesm_regridded.nc\")[\"zos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f7ea2-3d5f-4241-b366-086d207279e3",
   "metadata": {},
   "source": [
    "### Plot mean SSH field in reanalysis and model\n",
    "First, a function to plot the Gulf Stream region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9eb17-b5dc-423f-a952-082e38fc030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, a function to plot the North Atlantic\n",
    "def plot_setup_GS(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-80, -42]\n",
    "    lat_range = [30, 50]\n",
    "    xticks = [-70, -60, -50]\n",
    "    yticks = [35, 45]\n",
    "\n",
    "    ax, gl = plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd706c-8405-4e84-aee8-d582d0de57cd",
   "metadata": {},
   "source": [
    "Next, make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1aeb8e-c71f-4ccb-aa2f-51e5d34d6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(2, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "## ORAS5\n",
    "ax, gl = plot_setup_GS(ax)\n",
    "oras_plot = ax.contourf(\n",
    "    zos_oras.longitude,\n",
    "    zos_oras.latitude,\n",
    "    zos_oras.mean(\"time\"),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=make_cb_range(1, 0.1),\n",
    ")\n",
    "cb = fig.colorbar(oras_plot, ticks=[-1, 0, 1], label=r\"SSH ($m$)\")\n",
    "\n",
    "## CESM\n",
    "ax = fig.add_subplot(2, 1, 2, projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_GS(ax)\n",
    "cesm_plot = ax.contourf(\n",
    "    zos_cesm.longitude,\n",
    "    zos_cesm.latitude,\n",
    "    zos_cesm.mean(\"time\"),\n",
    "    cmap=\"cmo.balance\",\n",
    "    levels=make_cb_range(1, 0.1),\n",
    ")\n",
    "cb = fig.colorbar(cesm_plot, ticks=[-1, 0, 1], label=r\"SSH ($m$)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d2cb8-c516-4fef-bef8-8c939125a37f",
   "metadata": {},
   "source": [
    "### Identifying Gulf Stream position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc38357-1692-4753-829c-b8807f7e07b1",
   "metadata": {},
   "source": [
    "As discussed above, we can think of the SSH gradient as a proxy for velocity. Therefore, we can attempt to locate the Gulf Stream in the data as the local maximum in SSH gradient. Below, we write functions to do this: ```grad``` computes the SSH gradient, ```get_grad_mag``` computes the magnitude of the gradient, and ```get_GS_yposn``` identifies the \"y-position\" (latitude) of the Gulf Stream at each longitude on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffece44c-1f54-47e3-96d5-5a95bc4eef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(f):\n",
    "    \"\"\"compute gradient of data called 'f'.\n",
    "    assumes latitude and longitude are both increasing.\n",
    "    Returns df/dx and df/dy, both in units of mm/km\n",
    "    \"\"\"\n",
    "\n",
    "    ## get change in lon/lat (assume constant grid)\n",
    "    theta = np.deg2rad(f.longitude)\n",
    "    phi = np.deg2rad(f.latitude)\n",
    "    dtheta = theta.values[1] - theta.values[0]\n",
    "    dphi = phi.values[1] - phi.values[0]\n",
    "\n",
    "    ## get change in dx/dy\n",
    "    R = 6.37e6  # radius of earth in meters\n",
    "    dy = R * dphi\n",
    "    dx = R * np.cos(phi) * dtheta\n",
    "\n",
    "    ## get differences\n",
    "    f_plus = f.isel(longitude=slice(1, None))\n",
    "    f_minus = f.isel(longitude=slice(None, -1))\n",
    "    df_dy = xr.zeros_like(f_minus)\n",
    "    df = f_plus.values - f_minus.values\n",
    "    df_dy.values = df / dy\n",
    "\n",
    "    f_plus = f.isel(latitude=slice(1, None))\n",
    "    f_minus = f.isel(latitude=slice(None, -1))\n",
    "    df = xr.zeros_like(f_minus)\n",
    "    df.values = f_plus.values - f_minus.values\n",
    "    df_dx = df / dx\n",
    "\n",
    "    ## convert from units of m/m to mm/km\n",
    "    ## (equivalent to multiplying by 1e6)\n",
    "    df_dx *= 1e6\n",
    "    df_dy *= 1e6\n",
    "\n",
    "    return df_dx, df_dy\n",
    "\n",
    "\n",
    "def get_grad_mag(f):\n",
    "    \"\"\"get magnitude of gradient\"\"\"\n",
    "\n",
    "    # get gradient\n",
    "    df_dx, df_dy = grad(f)\n",
    "\n",
    "    ## get gradient magnitude\n",
    "    grad_mag = np.sqrt(df_dx**2 + df_dy**2)\n",
    "\n",
    "    ## smooth in space\n",
    "    n = 3\n",
    "    grad_mag = grad_mag.rolling({\"latitude\": n, \"longitude\": n}).mean()\n",
    "\n",
    "    return grad_mag\n",
    "\n",
    "\n",
    "def get_GS_yposn(grad_mag):\n",
    "    \"\"\"Get position of Gulf Stream based on magnitude of gradient\"\"\"\n",
    "\n",
    "    ## Trim in space\n",
    "    grad_mag_trimmed = grad_mag.sel(\n",
    "        longitude=slice(-80, None), latitude=slice(None, 45)\n",
    "    )\n",
    "\n",
    "    ## get gulf stream y_posn\n",
    "    y_posn = grad_mag_trimmed.latitude.isel(\n",
    "        latitude=grad_mag_trimmed.argmax(\"latitude\")\n",
    "    )\n",
    "\n",
    "    return y_posn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3c12c-f084-47b8-9f05-c4b29175b001",
   "metadata": {},
   "source": [
    "Let's apply these functions: compute magnitude of SSH gradient and Gulf Stream position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c4eaa-d81d-45ac-aeed-db67c00bce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get magnitude\n",
    "mag_oras = get_grad_mag(zos_oras)\n",
    "mag_cesm = get_grad_mag(zos_cesm)\n",
    "\n",
    "## get GS latitude\n",
    "y_posn_oras = get_GS_yposn(mag_oras)\n",
    "y_posn_cesm = get_GS_yposn(mag_cesm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537a4d5-5f24-4106-ba3c-b892e6490def",
   "metadata": {},
   "source": [
    "Finally, plot the SSH gradient of the time-mean (or a random sample) and overlay the estimated Gulf Stream position. Note: the Gulf Stream extends much farther east in the reanalysis compared to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f79d6-0813-4c8e-bce5-798ffbaf2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify whether to plot time mean or random sample\n",
    "plot_mean = True\n",
    "\n",
    "## specify colorbar max for each plot\n",
    "vmax = 10\n",
    "\n",
    "if plot_mean:\n",
    "    get_plot_data = lambda x: x.mean(\"time\")\n",
    "\n",
    "else:\n",
    "    t_idx = rng.choice(np.arange(len(y_posn_oras.time)))\n",
    "    get_plot_data = lambda x: x.isel(time=t_idx)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "for i, (mag, y_posn, name) in enumerate(\n",
    "    zip([mag_oras, mag_cesm], [y_posn_oras, y_posn_cesm], [\"reanalysis\", \"model\"]),\n",
    "    start=1,\n",
    "):\n",
    "\n",
    "    ax = fig.add_subplot(2, 1, i, projection=ccrs.PlateCarree())\n",
    "    ax, gl = plot_setup_GS(ax)\n",
    "    ax.set_title(f\"Magnitude of SSH gradient in {name}\")\n",
    "\n",
    "    ## Plot magnitude of gradient\n",
    "    plot = ax.contourf(\n",
    "        mag.longitude,\n",
    "        mag.latitude,\n",
    "        get_plot_data(mag),\n",
    "        cmap=\"cmo.amp\",\n",
    "        levels=np.linspace(0, vmax, 11),\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## Plot estimated position\n",
    "    ax.plot(y_posn.longitude, get_plot_data(y_posn), c=\"w\", ls=\"--\")\n",
    "\n",
    "    ## colorbar\n",
    "    cb = fig.colorbar(plot, ax=ax, ticks=[0, vmax], label=r\"mm / km\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04803ce2-3123-4db0-ba04-0876241ef4da",
   "metadata": {},
   "source": [
    "# To-do: validate a climate model\n",
    "Your task for this part of the tutorial is to validate a given climate model's ability to represent your climate index. Specifically, you'll choose a climate model from the CMIP archive and compare that model's output to that for the reanalysis product, for the overlapping period. If you don't have a preferred climate model, we suggest using the CESM2 model.\n",
    "\n",
    "One way to do this is by computing the index for the reanalysis and the model, and comparing their statistics (e.g., by plotting the histograms for each next to each other). However, it will probably be useful to make some basic plots before computing the index (e.g., how does the model's time-mean SST compare to the reanalysis in the region of interest?). \n",
    "\n",
    "Once you've made a few comparisons between the reanalysis and model, think about whether the model is suitable for assessing future changes to your climate index. If so, are there any caveats?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
